{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Complementary Energy\n",
    "\n",
    "Over the past two weeks, we have explored the displacement resulting from distributed pressure and the Hertz contact solution. Now, we shift our focus to real contact problems, emphasizing **Variational Principles** and the **Minimum Complementary Energy** approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Contact model discussed in first step](figures/Problem_mapping.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we simplify our model as the contact between a rigid rough surface and an elastic flat surface[4].\n",
    "\n",
    "![rigid rough surface elastic contact](figures/rigid_rough_surface_elastic_contact.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know pressure distribution $P(x,y)$, and we define our gap function as:\n",
    "\n",
    "$$\n",
    "g(x, y)=u_z(x, y)-h(x, y)\n",
    "$$\n",
    "\n",
    "where $u_z(x, y)$ is the normal displacement, the separation of two surfaces $h(x,y)$ can sometimes be $h(r)=-\\frac{r^2}{2 R}$, like Rey(2017)[5].\n",
    "\n",
    "As the first chapiter of Lucas(2020)[1], the potential energy can be derived from elastic energy relationship $\\frac{1}{2} \\int_v \\varepsilon: \\mathbb{C}: \\varepsilon d v$ to:\n",
    "\n",
    "$$\n",
    "E_p\\left(u_z, p\\right)=\\frac{1}{2} \\int_s u_z \\cdot p d s\n",
    "$$\n",
    "\n",
    "If we minimize this potential energy with respect to $u_z$, then we call it **Primal minimization problem**, we will end up with a displacement solution.\n",
    "\n",
    "$$\n",
    "\\min _{g\\left[u_z\\right] \\geqslant 0} E_p\\left(u_z, p\\left[u_z\\right]\\right)\n",
    "$$\n",
    "\n",
    "Here we focus on complementary energy minimization, called **Dual minimization problem**, where complementary energy is defined as:\n",
    "\n",
    "$$\n",
    "E_c\\left(u_z, p\\right)=\\frac{1}{2} \\int_s u_z \\cdot p d s-\\int_s p h d s\n",
    "$$\n",
    "\n",
    "Then the minimization could be:\n",
    "\n",
    "$$\n",
    "\\min _{p \\geqslant 0} E_c\\left(u_z[p], p\\right)\n",
    "$$\n",
    "\n",
    "It is obvious that we will end up with a pressure solution in this procedure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Legendre transform for dual optimization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we discuss above, we have two constraints, \n",
    "\n",
    "$$\n",
    "\\frac{1}{S} \\int_s p d s=\\bar{p}\n",
    "$$\n",
    "\n",
    "And\n",
    "\n",
    "$$\n",
    "p \\geq 0\n",
    "$$\n",
    "\n",
    "To minimize the complementary energy, we consider:\n",
    "\n",
    "$$\n",
    "\\lim _{\\varepsilon \\rightarrow 0} \\frac{E_c(p+\\varepsilon v)-E_c(p)}{\\varepsilon}\n",
    "$$\n",
    "\n",
    "Here we can derive a gap function by:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E_c}{\\partial p}=u_z[p]-h=g\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the same background as a start point to verify this energy minimization, and define $ \\bar{p}=\\frac{W}{S} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *$u_z$* is our unknown in this case, but we know the relationship between *$u_z$* and pressure *$P$*, we will then treat *$u_z$* as *$u_z(P)$*. The Hertz solution is derived from elastic theory, here we want to derive from energy theory, finally we can compare with Hertz solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Complementary energy minimization for Normal contact\n",
    "\n",
    "We follow the steps of Lucas(2020)[1], and finally we will have two alrgorithms to implement, Steepest descent[6] and Constrained conjugate gradient[7]. First we give the notation as reference:\n",
    "\n",
    "Let the open $\\mathcal{B} \\subset \\mathbb{R}^3$ be a deformable elastic solid of boundary $\\partial \\mathcal{B}$ with outward normal $\\boldsymbol{n}$. Let $u$ be the displacement vector field of $\\mathcal{B}$.\n",
    "\n",
    "We have the following strain-stress relationship in the context of continuum mechanics and elasticity theory:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\varepsilon}[\\boldsymbol{u}]:=\\frac{1}{2}\\left(\\boldsymbol{\\nabla} \\boldsymbol{u}+\\boldsymbol{\\nabla} \\boldsymbol{u}^T\\right)\n",
    "$$\n",
    "$$\n",
    "\\sigma[u]:=C: \\varepsilon[u]\n",
    "$$\n",
    "\n",
    "We define the traction vector of the displacement field $\\boldsymbol{u}$ as:\n",
    "\n",
    "$$\n",
    "T[u]:=\\left.\\sigma[u]\\right|_{\\partial \\mathcal{B}} \\cdot \\boldsymbol{n}\n",
    "$$\n",
    "\n",
    "$\\boldsymbol{b}$ is given as the volumetric force density, then with given boundary condition, we can express the principle of minimum potential energy:\n",
    "\n",
    "$$\n",
    "\\inf _{\\boldsymbol{u} \\in \\mathrm{KA}(\\mathcal{B})}\\left\\{I(\\boldsymbol{u})=\\frac{1}{2} \\int_{\\mathcal{B}} \\boldsymbol{\\sigma}[\\boldsymbol{u}]: \\boldsymbol{\\varepsilon}[\\boldsymbol{u}] \\mathrm{d} V-\\int_{\\mathcal{B}} \\boldsymbol{b} \\cdot \\boldsymbol{u} \\mathrm{d} V-\\int_{\\partial \\mathcal{B}} T[\\boldsymbol{u}] \\cdot \\boldsymbol{u} \\mathrm{d} S\\right\\}\n",
    "$$\n",
    "\n",
    "which involves finding $u \\in \\mathrm{KA}(\\mathcal{B})$, i.e. a kinematically admissible displacement field, that minimizes the total potential energy of the system.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned before, we want to minimize complementary energy for a non-friction, non-adhesion contact between the boundary $\\partial \\mathcal{B}$ and a surface $\\mathcal{S}$, we can introduce the gap function as:\n",
    "\n",
    "$$\n",
    "g[\\boldsymbol{u}]:=\\left.\\boldsymbol{u} \\cdot \\boldsymbol{e}_3\\right|_{\\partial \\mathcal{B}}-h\n",
    "$$\n",
    "\n",
    "The boundary conditions on $\\partial \\mathscr{B}$ are hence expressed with the Hertz-Signorini-Moreau conditions:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "g[\\boldsymbol{u}] & \\geq 0 \\\\\n",
    "p[\\boldsymbol{u}]:=\\boldsymbol{T}[\\boldsymbol{u}] \\cdot \\boldsymbol{e}_3 & \\geq 0 \\\\\n",
    "g[\\boldsymbol{u}] p[\\boldsymbol{u}] & =0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The contact condition that we want to apply for **Steepest descent** algorithm as stopping criteria is:\n",
    "\n",
    "$$\n",
    "g[\\boldsymbol{u}] p[\\boldsymbol{u}]=0\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational form\n",
    "\n",
    "For this contact problem, we have two constraints, \n",
    "\n",
    "$$\n",
    "\\frac{1}{S} \\int_s p d s=\\bar{p}\n",
    "$$\n",
    "\n",
    "And\n",
    "\n",
    "$$\n",
    "p \\geq 0\n",
    "$$\n",
    "\n",
    "To introduce the contact constraints, one needs to define the space of kinematically admissible displacement fields $\\mathrm{KA}(\\mathcal{B})$. The first consideration defines the function space\n",
    "\n",
    "$$\n",
    "\\bar{H}^1\\left(\\mathcal{B}_p ; \\mathbb{R}^3\\right)=\\left\\{\\boldsymbol{u}+\\overline{\\boldsymbol{u}} \\mid \\boldsymbol{u} \\in H^1\\left(\\mathcal{B}_p ; \\mathbb{R}^3\\right), \\overline{\\boldsymbol{u}} \\in \\mathbb{R}^3 \\text { with } \\widehat{\\mathbf{u}}(\\mathbf{0}, \\bullet)=0\\right\\}\n",
    "$$\n",
    "\n",
    "which is a space of $\\mathcal{B}_p$-periodic functions whose fundamental mode (i.e. the horizontal average) is constant with respect to $x_3$. The space of admissible solutions to the contact problem is:\n",
    "\n",
    "$$\n",
    "\\mathrm{KA}\\left(\\mathcal{B}_p\\right):=\\left\\{\\boldsymbol{u} \\in \\bar{H}^1\\left(\\mathcal{B}_p ; \\mathbb{R}^3\\right): g[\\boldsymbol{u}] \\geq 0\\right\\}\n",
    "$$\n",
    "\n",
    "The minimization principle is then written as:\n",
    "\n",
    "$$\n",
    "\\inf _{\\boldsymbol{u} \\in \\operatorname{KA}\\left(\\mathcal{B}_p\\right)}\\left\\{\\frac{1}{2} \\int_{\\mathcal{B}_p} \\boldsymbol{\\sigma}[\\boldsymbol{u}]: \\boldsymbol{\\varepsilon}[\\boldsymbol{u}] \\mathrm{d} V\\right\\}\n",
    "$$\n",
    "\n",
    "which is a quadratic program with unilateral constraints. Kalker(1977)[3] has shown that the above problem can be expressed only in terms of boundary integrals, provided $\\boldsymbol{u}$ additionally satisfies the local equilibrium(strong Euler-Lagrange equation) $\\operatorname{div}(\\sigma[\\boldsymbol{u}])+\\boldsymbol{b}=\\mathbf{0} \\quad \\text { a.e. in } \\mathcal{B}$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{1}{2} \\int_{\\mathcal{B}_p} \\sigma[\\boldsymbol{u}]: \\boldsymbol{\\varepsilon}[\\boldsymbol{u}] \\mathrm{d} V & =\\frac{1}{2} \\int_{\\mathcal{B}_p} \\boldsymbol{\\sigma}[\\boldsymbol{u}]: \\boldsymbol{\\nabla} \\boldsymbol{u} \\mathrm{d} V \\\\\n",
    "& =\\frac{1}{2} \\int_{\\mathcal{B}_p}(\\operatorname{div}(\\sigma[\\boldsymbol{u}] \\cdot \\boldsymbol{u})-\\operatorname{div}(\\sigma[\\boldsymbol{u}]) \\cdot \\boldsymbol{u}) \\mathrm{d} V \\\\\n",
    "& =\\frac{1}{2} \\int_{\\partial \\mathcal{B}_p} \\boldsymbol{u} \\cdot \\boldsymbol{\\sigma}[\\boldsymbol{u}] \\cdot \\boldsymbol{n} \\mathrm{d} V\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "so that the contact problem is equivalent to\n",
    "\n",
    "$$\n",
    "\\inf _{\\boldsymbol{u} \\in \\operatorname{KA}\\left(\\mathcal{B}_p\\right)}\\left\\{I_u(\\boldsymbol{u})=\\frac{1}{2} \\int_{\\partial \\mathcal{B}_p} \\boldsymbol{T}[\\boldsymbol{u}] \\cdot \\boldsymbol{u} \\mathrm{d} S\\right\\}\n",
    "$$\n",
    "\n",
    "This minimization problem can now be solved by quadratic programming (see Rey(2017)[5]), but optimization techniques are usually applied to the dual of $\\inf _{\\boldsymbol{u} \\in \\operatorname{KA}\\left(\\mathcal{B}_p\\right)}\\left\\{I_u(\\boldsymbol{u})=\\frac{1}{2} \\int_{\\partial \\mathcal{B}_p} \\boldsymbol{T}[\\boldsymbol{u}] \\cdot \\boldsymbol{u} \\mathrm{d} S\\right\\}$, which we derive by associating a Lagrange multiplier $\\lambda$ to the non-penetration constraint $g[\\boldsymbol{u}] \\geq 0$.  The Lagrangian of the problem is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: quadratic programming, dual problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}(\\boldsymbol{u}, \\lambda)=\\frac{1}{2} \\int_{\\partial \\mathcal{B}_p} \\boldsymbol{T}[\\boldsymbol{u}] \\cdot \\boldsymbol{u} \\mathrm{d} S-\\int_{\\partial \\mathcal{B}_p} \\lambda\\left(\\boldsymbol{u} \\cdot \\boldsymbol{e}_3-h\\right) \\mathrm{d} S\n",
    "$$\n",
    "\n",
    "The Karush-Kuhn-Tucker optimality conditions imply stationarity of $\\mathcal{L}$ with respect to $\\boldsymbol{u}$ so that we can express $\\lambda$ :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{u}}=\\mathbf{0} & \\Leftrightarrow T[u]-\\lambda \\boldsymbol{e}_3=0 \\\\\n",
    "& \\Leftrightarrow \\lambda=T[\\boldsymbol{u}] \\cdot \\boldsymbol{e}_3 \\\\\n",
    "& \\Leftrightarrow \\boldsymbol{u}=\\mathcal{M}\\left[\\lambda \\boldsymbol{e}_3\\right] \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda$ can be physically interpreted as the normal tractions acting on the surface. Replacing $\\boldsymbol{u}=\\mathcal{M}\\left[p \\boldsymbol{e}_3\\right]$ in $\\mathcal{L}$ (effectively computing the Legendre transform of $I_u$ ) leads to the quadratic program\n",
    "\n",
    "$$\n",
    "\\inf _{p \\boldsymbol{e}_3 \\in \\mathrm{SA}\\left(\\mathcal{B}_p\\right)}\\left\\{I_p(p)=\\frac{1}{2} \\int_{\\partial \\mathcal{B}_p} p \\boldsymbol{e}_3 \\cdot \\mathcal{M}\\left[p \\boldsymbol{e}_3\\right] \\mathrm{d} S-\\int_{\\partial \\mathcal{B}_p} p h \\mathrm{~d} S\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the primary unknown $p$ is the normal surface traction and SA is the space of statically admissible tractions, i.e. tractions that satisfy $p \\geq 0$ (for non-adhesive contact) and $\\int_{\\partial \\mathcal{B}} p \\mathrm{~d} S=$ $W$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just not to be confused, $W$ is normal total load and we define $ \\bar{p}=\\frac{W}{S} $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import LinearConstraint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define the parameters\n",
    "W = 1e2  # total load\n",
    "R = 1  # radius of demi-sphere\n",
    "L = 2  # domain size\n",
    "S = L**2  # domain area\n",
    "\n",
    "\n",
    "\n",
    "#define material parameters\n",
    "E = 1e3  # Young's modulus\n",
    "nu = 0.3  # Poisson's ratio\n",
    "E_star = E / (1 - nu**2)  # plane strain modulus \n",
    "\n",
    "#We generate a 2D coordinate space\n",
    "n = 100\n",
    "m = 100\n",
    "\n",
    "x, y = np.meshgrid(np.linspace(0, L, n, endpoint=False), np.linspace(0, L, m, endpoint=False))#notice here that we use endpoint=False to avoid having the last point\n",
    "\n",
    "x0 = 1\n",
    "y0 = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40866510127815564 285.8948173079934\n"
     ]
    }
   ],
   "source": [
    "# Based on the analytical solution, we can print the value of a and p0 as reference\n",
    "a = (3*W*R/(4*E_star))**(1/3)\n",
    "p0 = (6*W*E_star**2/(np.pi**3*R**2))**(1/3)\n",
    "\n",
    "print(a, p0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the separation function h depends on the contact model, since we just use a simple semi-sphere/flat surface contact, we keep it as $h(r)=-\\frac{r^2}{2 R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the separation h_matrix          #Since we are using the same model, we can use the same h function\n",
    "h_matrix = - (x**2 + y**2)/(2*R)\n",
    "\n",
    "# Initial pressure distribution\n",
    "p_initial = np.full((n, m), W / S).flatten()  # Flatten for optimization\n",
    "\n",
    "# Fourier transform of initial pressure distribution\n",
    "P_fourier_flattened = np.fft.fft2(p_initial.reshape(n, m), norm='ortho').flatten()  # Keep flattened\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimization with FFT\n",
    "\n",
    "First we use **scipy** library functions, *scipy.optimize.minimize* and *scipy.optimize.LinearConstraint* and FFT method with the nice property for convolution integral. We have the following convolution product:\n",
    "\n",
    "$$\n",
    "\\mathcal{F}(u)= \\mathcal{F}(f) \\bullet \\mathcal{F}(p) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to define our Kernel function in fourrier domain:\n",
    "\n",
    "$$\n",
    "\\mathcal{F}(f)=\\frac{2}{E^* \\sqrt{q_x^2+q_y^2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define the frequency with q_x and q_y\n",
    "q_x = 2 * np.pi * np.fft.fftfreq(n, d=L/n)\n",
    "q_y = 2 * np.pi * np.fft.fftfreq(m, d=L/m)\n",
    "QX, QY = np.meshgrid(q_x, q_y)\n",
    "\n",
    "kernel_fourier = np.zeros_like(QX)  # Initialize the kernel array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible to have negative value, because we set the *average value $C_0$* to be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/9pns8j3d2sl62pk5rmmfs01h0000gn/T/ipykernel_6097/2267934034.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  kernel_fourier = 2 / (E_star * np.sqrt(QX**2 + QY**2))\n"
     ]
    }
   ],
   "source": [
    "#non_zero_indices = (QX**2 + QY**2) != 0  # Avoid division by zero\n",
    "kernel_fourier = 2 / (E_star * np.sqrt(QX**2 + QY**2))\n",
    "kernel_fourier[0, 0] = 0  # Set the zero frequency component to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the instructions above, we have the formula for complementary energy:\n",
    "$$\n",
    "E_c\\left(u_z, p\\right)=\\frac{1}{2} \\int_s u_z \\cdot p d s-\\int_s p h d s\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We call our complementary energy as cost function\n",
    "def cost_function(P_flattened, kernel_fourier, h_matrix):\n",
    "    # Ensure kernel_fourier and h_matrix are correctly shaped and prepared before this function is called\n",
    "    \n",
    "    # Reshape P_fourier_flattened back to its 2D shape to perform operations\n",
    "    P_flattened = P_flattened.reshape((n, m))\n",
    "    P_fourier = np.fft.fft2(P_flattened, norm='ortho')\n",
    "    \n",
    "    # Calculate u_z in the Fourier domain\n",
    "    u_z_fourier = P_fourier * kernel_fourier\n",
    "    \n",
    "    # Transform u_z back to the spatial domain to compute the cost function\n",
    "    u_z = np.fft.ifft2(u_z_fourier, norm='ortho').real\n",
    "    \n",
    "    # Calculate the first term of the cost function: 0.5 * sum(u_z * P), where P is also in the spatial domain\n",
    "    term1 = 0.5 * np.sum(u_z * P_flattened)\n",
    "    \n",
    "    # Calculate the second term of the cost function: sum(P * h)\n",
    "    term2 = np.sum(P_flattened * h_matrix)\n",
    "    \n",
    "    # The cost function is the difference of the two terms\n",
    "    cost = term1 - term2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have the formula for gap function:\n",
    "\n",
    "$$\n",
    "g[\\boldsymbol{u}]:=\\left.\\boldsymbol{u} \\cdot \\boldsymbol{e}_3\\right|_{\\partial \\mathcal{B}}-h\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the gradient of the cost function as jacobian\n",
    "# the gradient of the cost function is actually the gap function\n",
    "def gradient(P_flattened, kernel_fourier, h_matrix):\n",
    "    # Ensure kernel_fourier and h_matrix are correctly shaped and prepared before this function is called\n",
    "    \n",
    "    # Reshape P_fourier_flattened back to its 2D shape to perform operations\n",
    "    P_fourier = np.fft.fft2(P_flattened.reshape((n, m)), norm='ortho')\n",
    "    \n",
    "    # Calculate u_z in the Fourier domain\n",
    "    u_z_fourier = P_fourier * kernel_fourier\n",
    "    \n",
    "    # Transform u_z back to the spatial domain to compute the cost function\n",
    "    u_z = np.fft.ifft2(u_z_fourier, norm='ortho').real\n",
    "\n",
    "    return (u_z - h_matrix).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten kernel_fourier and h_matrix if they are not already flattened, depending on how you pass them to the function\n",
    "kernel_fourier_flattened = kernel_fourier.flatten()\n",
    "h_matrix_flattened = h_matrix.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lizichen/anaconda3/lib/python3.11/site-packages/scipy/optimize/_trustregion_constr/minimize_trustregion_constr.py:315: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x0 = np.atleast_1d(x0).astype(float)\n"
     ]
    }
   ],
   "source": [
    " # define the length of the pressure vector\n",
    "length = len(P_fourier_flattened)  # p_bar is initial guess for the pressure\n",
    "# first non_negative_constraint for the pressure\n",
    "non_negative_constraint = LinearConstraint(np.eye(length), np.zeros(length), np.inf*np.ones(length))\n",
    "\n",
    "# second avarage_constraint for the pressure\n",
    "average_pressure_constraint = LinearConstraint(np.ones((1,length))/(length), W/S, W/S)\n",
    "\n",
    "jac = lambda P_fourier_flattened: gradient(P_fourier_flattened, kernel_fourier, h_matrix)\n",
    "\n",
    "\n",
    "\n",
    "result = minimize(lambda P_fourier_flattened: cost_function(P_fourier_flattened, kernel_fourier, h_matrix), P_fourier_flattened, method='trust-constr', jac=jac, constraints=[non_negative_constraint, average_pressure_constraint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the result\n",
    "# .x refers to an attribute of the object result, which is returned by the minimize function from the scipy.optimize module in Python.\n",
    "P_optimized_fourier = result.x.reshape((n, m))\n",
    "\n",
    "displacement_optimized_fourier = P_optimized_fourier * kernel_fourier\n",
    "displacement_optimized_real = np.fft.ifft2(displacement_optimized_fourier, norm='ortho').real\n",
    "\n",
    "#print(displacement_optimized_real)\n",
    "\n",
    "#plot P_optimized_fourier\n",
    "plt.imshow(P_optimized_fourier, cmap='jet', origin='lower', extent=[0, L, 0, L])\n",
    "print(P_optimized_fourier.mean())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We apply Hertz solution for comparasion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we give our analytical normal displacement solution by Hertz\n",
    "\n",
    "$$\n",
    "\\bar{u}_z=\\frac{1-\\nu^2}{E} \\frac{\\pi p_0}{4 a}\\left(2 a^2-r^2\\right), \\quad r \\leqslant a\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_value = 1e2 \n",
    "\n",
    "#We keep other material parameters the same\n",
    "\n",
    "# We define the distance from the center of the sphere\n",
    "r = np.sqrt((x-x0)**2 + (y-y0)**2)\n",
    "\n",
    "u_z = -(r**2)/(2*R)\n",
    "\n",
    "# Correctly applying the displacement outside the contact area\n",
    "outside_contact = r > a\n",
    "u_z_outside = -(r[outside_contact]**2)/(2*R) + a * np.sqrt(r[outside_contact]**2 - a**2)/(np.pi*R) + (r[outside_contact]**2-2*a**2)*np.arccos(a/r[outside_contact])/(np.pi*R)\n",
    "u_z[outside_contact] = u_z_outside\n",
    "\n",
    "#plot u_z\n",
    "plt.imshow(u_z, cmap='viridis', origin='lower', extent=[0, L, 0, L])\n",
    "plt.colorbar(label='Displacement (u_z)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Displacement Field')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "## The following is comparasion of the two solutions\n",
    "#######################################################\n",
    "\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Calculate the error between the real part of the displacement obtained through FFT and the analytical solution\n",
    "error = np.abs(displacement_optimized_real - np.max(displacement_optimized_real) - u_z)\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create a surface plot of the error\n",
    "X, Y = np.meshgrid(np.linspace(0, L, n), np.linspace(0, L, m))\n",
    "surf = ax.plot_surface(X, Y, error, cmap='viridis', edgecolor='none')\n",
    "\n",
    "# Add a color bar which maps values to colors\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Error')\n",
    "ax.set_title('Error between Analytical and Fourier Method Displacement')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one more notation that needs to be clarified, $\\mathcal{M}$ is a boundary integral operator defined in terms of fundamental solutions. Consequently, the integral operator $\\mathcal{M}$ can be expressed as a convolution with respect to the horizontal coordinates. \n",
    "\n",
    "The gradient computation of the functional $I_p$ is straightforward with the use of $\\mathcal{M}$:\n",
    "\n",
    "$$\n",
    "\\nabla I_p(p)=\\mathcal{M}\\left[p \\boldsymbol{e}_3\\right] \\cdot \\boldsymbol{e}_3-h=u_3-h=g\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steepest descent algorithm\n",
    "\n",
    "The approach proposed by Stanley and Kato(1997)[6] consists in taking steps in the $-\\nabla I_p=-g$ direction then shifting and truncating the normal traction so that both the unilateral and equilibrium constraints are satisfied. Besides, its convergence rate is sub-optimal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1: Stanley and Kato (1997) steepest descent algorithm.\n",
    "\n",
    "**Inputs:** normal total load  $W$, surface profile $\\mathbf{H}$, tolerance  $\\varepsilon$, maximum number of iterations  $N_{\\text{max}}$.\n",
    "\n",
    "1. Initialize $ P $ with the average constant load initial guess:\n",
    "   $$ P \\leftarrow \\frac{W}{|\\partial \\mathbf{B}P|} $$\n",
    "2. Set $ h_{\\text{norm}} $ to the norm of  $\\mathbf{H}$ :\n",
    "   $$ h_{\\text{norm}} \\leftarrow \\|\\mathbf{H}\\| $$\n",
    "3. Set iteration counter $ k $ to zero:\n",
    "   $$ k \\leftarrow 0 $$\n",
    "\n",
    "**Repeat until** $ e < \\varepsilon $ **or** $ k > N_{\\text{max}} $:\n",
    "\n",
    "4. Calculate the gradient $ G $:\n",
    "   $$ G \\leftarrow M[\\mathbf{P}e_3] \\cdot e_3 - \\mathbf{H} $$\n",
    "5. Update $ P $ by subtracting $ G $:\n",
    "   $$ P \\leftarrow P - G $$\n",
    "6. Find $ \\alpha_0 $ that solves the following equation (where $ (\\bullet)_+ $ is the ramp function):\n",
    "   $$ \\text{Find } \\alpha_0 \\text{ solution of } \\Sigma (P + \\alpha_0)_+ - W = 0 $$\n",
    "7. Update $ P $ with $ \\alpha_0 $:\n",
    "   $$ P \\leftarrow (P + \\alpha_0)_+ $$\n",
    "8. Calculate the error on complementarity $ e $:\n",
    "   $$ e \\leftarrow |P \\cdot (G - \\min(G))|/(Wh_{\\text{norm}}) $$\n",
    "9. Increment the iteration counter $ k $:\n",
    "   $$ k \\leftarrow k + 1 $$\n",
    "\n",
    "**After exiting the loop**:\n",
    "\n",
    "10. Ensure a positive gap by updating \\( G \\):\n",
    "    $$ G \\leftarrow G - \\min(G) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same settings as before for material parameters and discretization\n",
    "\n",
    "# Initial pressure distribution\n",
    "P = np.full((n, m), W / S)  # Initial guess for the pressure\n",
    "\n",
    "#same frequency components for fourier transform\n",
    "\n",
    "# Initialize variables for the iteration\n",
    "tol = 1e-6  # Tolerance for convergence\n",
    "iter_max = 10000  # Maximum number of iterations\n",
    "k = 0  # Iteration counter\n",
    "error = np.inf  # Initialize error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in the solution loop, we need a root-finding function for $\\alpha_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_alpha_0(P, W, alpha_l, alpha_r, tol):\n",
    "    # approximates a root, R, of f bounded \n",
    "    # by a and b to within tolerance \n",
    "    # | f(m) | < tol with m the midpoint \n",
    "    # between a and b Recursive implementation\n",
    "    \n",
    "    \n",
    "    def f(alpha):\n",
    "        return np.mean(P + alpha) - W/S #since we give mean function, we should apply the avarge loading\n",
    "    \n",
    "    # check if a and b bound a root\n",
    "    while np.sign(f(alpha_l)) == np.sign(f(alpha_r)):\n",
    "        alpha_r *= 2\n",
    "        #raise Exception(f\"The scalars alpha_l and alpha_r do not bound a root {np.sign(f(alpha_l))} {np.sign(f(alpha_r))}\")\n",
    "    # get midpoint\n",
    "    alpha_c = (alpha_l + alpha_r)/2\n",
    "    \n",
    "\n",
    "    if np.abs(f(alpha_c)) < tol:\n",
    "        # stopping condition, report alpha_c as root\n",
    "        return alpha_c\n",
    "    elif np.sign(f(alpha_l)) == np.sign(f(alpha_c)):\n",
    "        # case where m is an improvement on a. \n",
    "        # Make recursive call with a = m\n",
    "        return find_alpha_0(P, W, alpha_c, alpha_r, tol)\n",
    "    elif np.sign(f(alpha_r)) == np.sign(f(alpha_c)):\n",
    "        # case where m is an improvement on b. \n",
    "        # Make recursive call with b = m\n",
    "        return find_alpha_0(P, W, alpha_l, alpha_c, tol)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while np.abs(error) > tol and k < iter_max:\n",
    "    # Calculate the gradient G in the Fourier domain and transform it back to the spatial domain\n",
    "    P_fourier = np.fft.fft2(P, norm='ortho')\n",
    "    G_fourier = P_fourier * kernel_fourier\n",
    "    G = np.fft.ifft2(G_fourier, norm='ortho').real - h_matrix\n",
    "    \n",
    "    # Update P by subtracting G\n",
    "    P = P - G\n",
    "    \n",
    "    # Ensure P is non-negative\n",
    "    P = np.maximum(P, 0)\n",
    "    \n",
    "    # Adjust P to satisfy the total load constraint\n",
    "    alpha_0 = find_alpha_0(P, W/S, -np.max(P), W, tol)\n",
    "    #alpha_0 = find_alpha_0(P, W, -1e2, 1e2, 1e-6)\n",
    "    P += alpha_0\n",
    "    P[P < 0] = 0\n",
    "    \n",
    "    # Calculate the error for convergence checking\n",
    "    error = np.vdot(P, (G - np.min(G))) / (P.size*W) #/ np.linalg.norm(h_matrix)\n",
    "    print(error, k)\n",
    "    \n",
    "    k += 1  # Increment the iteration counter\n",
    "\n",
    "\n",
    "# Ensure a positive gap by updating G\n",
    "G = G - np.min(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacement_fourier = P_fourier * kernel_fourier\n",
    "displacement = np.fft.ifft2(displacement_fourier, norm='ortho').real\n",
    "\n",
    "plt.imshow(P, cmap='jet', origin='lower', extent=[0, L, 0, L])\n",
    "plt.colorbar(label='Pressure (P)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Pressure Field')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we give our analytical normal displacement solution by Hertz\n",
    "\n",
    "$$\n",
    "\\bar{u}_z=\\frac{1-\\nu^2}{E} \\frac{\\pi p_0}{4 a}\\left(2 a^2-r^2\\right), \\quad r \\leqslant a\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Hertz solution has been computed before, the comparasion is given as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Calculate the error between the real part of the displacement obtained through FFT and the analytical solution\n",
    "error = np.abs(displacement - np.max(displacement) - u_z)\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create a surface plot of the error\n",
    "X, Y = np.meshgrid(np.linspace(0, L, n), np.linspace(0, L, m))\n",
    "surf = ax.plot_surface(X, Y, error, cmap='viridis', edgecolor='none')\n",
    "\n",
    "# Add a color bar which maps values to colors\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Error')\n",
    "ax.set_title('Error between Analytical and Fourier Method Displacement')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate gradient algorithm\n",
    "\n",
    "The method proposed by Polonsky and Keer (1999b)[7] is a variation of a conjugate gradient algorithm with an active set to accelerate the convergence. As expected from numerical linear algebra, it outperforms the steepest descent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparasion with other online solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "\n",
    "[1] Frérot, Lucas Henri Galilée. ‘Bridging Scales in Wear Modeling with Volume Integral Methods for Elastic-Plastic Contact’, n.d.\n",
    "\n",
    "[2] Yastrebov, Vladislav A. Numerical Methods in Contact Mechanics. Numerical Methods in Engineering Series. Hoboken, NJ: Wiley, 2013.\n",
    "\n",
    "[3] Kalker, J. J. ‘Variational Principles of Contact Elastostatics’. IMA Journal of Applied Mathematics 20, no. 2 (1977): 199–219. https://doi.org/10.1093/imamat/20.2.199.\n",
    "\n",
    "[4] Vladislav A. Yastrebov, Contact mechanics and elements of tribology, Lecture 4.b, Contact and transport at small scales, Open Course Contact Mechanics and Elements of Tribology, January 23, 2024, https://cmet.yastrebov.fr/index.html\n",
    "\n",
    "[5] Rey, Valentine, Guillaume Anciaux, and Jean-François Molinari. ‘Normal Adhesive Contact on Rough Surfaces: Efficient Algorithm for FFT-Based BEM Resolution’. Computational Mechanics 60, no. 1 (July 2017): 69–81. https://doi.org/10.1007/s00466-017-1392-5.\n",
    "\n",
    "[6] Stanley, H. M., and T. Kato. ‘An FFT-Based Method for Rough Surface Contact’. Journal of Tribology 119, no. 3 (1 July 1997): 481–85. https://doi.org/10.1115/1.2833523.\n",
    "\n",
    "[7] Polonsky, I.A., and L.M. Keer. ‘A Numerical Method for Solving Rough Contact Problems Based on the Multi-Level Multi-Summation and Conjugate Gradient Techniques’. Wear 231, no. 2 (July 1999): 206–19. https://doi.org/10.1016/S0043-1648(99)00113-1.\n",
    "\n",
    "[8] https://gitlab.com/tamaas/tamaas/-/blob/master/examples/scipy_penalty.py?ref_type=heads\n",
    "\n",
    "[9] https://www.pecms.cn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
